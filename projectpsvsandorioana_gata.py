# -*- coding: utf-8 -*-
"""ProjectPSVsandorIOANA_GATA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qXdBXU61syO6ehH0JmfrFJ5NZbpwnWxn
"""

# Instalarea si importul  bibliotecilor
!pip install librosa matplotlib numpy scipy scikit-learn tensorflow pandas
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
from scipy import signal
from sklearn.decomposition import FastICA
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, LSTM
from tensorflow.keras.optimizers import Adam
from IPython.display import Audio, display
import os
import glob
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
print("Bibliotecile au fost importate cu succes!")

# Montăm Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Definim căile către arhive
DRIVE_PATH = '/content/drive/MyDrive'
URBANSOUND_PATH = '/content/UrbanSound8K'
LIBRISPEECH_PATH = '/content/LibriSpeech'

# Extragem arhiva UrbanSound8K
!mkdir -p /content/UrbanSound8K
!tar -xzf "/content/drive/MyDrive/UrbanSound8K.tar.gz" -C /content/UrbanSound8K

# Extragem arhiva LibriSpeech (dacă există)
!mkdir -p /content/LibriSpeech
!tar -xzf "/content/drive/MyDrive/test-clean.tar.gz" -C /content/LibriSpeech

print("Arhivele au fost extrase!")

# Importurile necesare
import numpy as np              # Pentru calcule numerice și arrays
import matplotlib.pyplot as plt # Pentru vizualizarea datelor
import librosa                  # Bibliotecă pentru procesarea audio
import librosa.display          # Pentru afișarea vizualizărilor audio
from IPython.display import Audio, display # Pentru redarea audio în notebook
import os                       # Pentru manipularea fișierelor și directoarelor
import random                   # Pentru selecții aleatoare
import glob                     # Pentru căutarea fișierelor după pattern

# Verifică existența directoarelor configurate anterior
print(f"Verificăm directoarele și fișierele...")
print(f"LIBRISPEECH_PATH: {LIBRISPEECH_PATH} - {'există' if os.path.exists(LIBRISPEECH_PATH) else 'nu există'}")
print(f"URBANSOUND_PATH: {URBANSOUND_PATH} - {'există' if os.path.exists(URBANSOUND_PATH) else 'nu există'}")

# Definirea funcției pentru încărcarea vocilor din setul de date LibriSpeech
def load_voices_from_librispeech(num_voices=3):
    voices = []          # Lista pentru stocarea semnalelor audio
    voice_names = []     # Lista pentru stocarea numelor vocilor

    flac_files = []      # Lista pentru stocarea căilor către fișierele FLAC
    # Parcurge recursiv toate directoarele pentru a găsi fișierele FLAC
    for root, dirs, files in os.walk(LIBRISPEECH_PATH):
        for file in files:
            if file.endswith('.flac'):    # Verifică dacă fișierul este de tip FLAC
                flac_files.append(os.path.join(root, file))   # Adaugă calea completă

    print(f"Am găsit {len(flac_files)} fișiere FLAC în LibriSpeech")

    # Verifică dacă s-au găsit fișiere FLAC
    if not flac_files:
        print(f"EROARE: Nu s-au găsit fișiere FLAC în directorul {LIBRISPEECH_PATH}")
        return [], [], 22050    # Returnează liste goale și rata implicită de eșantionare

    # Identificarea diferiților vorbitori din fișierele găsite
    speakers = {}    # Dicționar pentru maparea ID-urilor vorbitorilor la fișierele lor
    for file_path in flac_files:
        parts = file_path.split(os.sep)   # Împarte calea în componente
        for part in parts:
            if part.isdigit() and len(part) <= 5:  # Caută ID-uri de vorbitori (numere cu maxim 5 cifre)
                speaker_id = part
                if speaker_id not in speakers:
                    speakers[speaker_id] = []      # Inițializează lista pentru vorbitor dacă nu există
                speakers[speaker_id].append(file_path)  # Adaugă calea fișierului la lista vorbitorului
                break

    print(f"Am identificat {len(speakers)} vorbitori diferiți")

    # Selectează aleator un număr specificat de vorbitori
    selected_speakers = list(speakers.keys())
    if len(selected_speakers) > num_voices:
        selected_speakers = random.sample(selected_speakers, num_voices)

    # Încarcă un fișier audio pentru fiecare vorbitor selectat
    for i, speaker_id in enumerate(selected_speakers):
        # Alege primul fișier disponibil pentru acest vorbitor
        file_path = speakers[speaker_id][0]
        try:
            # Încarcă fișierul audio, păstrând rata originală de eșantionare
            voice, voice_sr = librosa.load(file_path, sr=None)
            # Limitează semnalul la 5 secunde
            if len(voice) > 5 * voice_sr:
                voice = voice[:5 * voice_sr]
            voice = voice / np.max(np.abs(voice))   # Normalizează semnalul la [-1, 1]
            voices.append(voice)                     # Adaugă semnalul la lista de voci
            voice_names.append(f"Voce {i+1} (ID {speaker_id})")  # Adaugă numele vocii
            print(f"Voce încărcată: {file_path}")
        except Exception as e:
            print(f"Eroare la încărcarea vocii: {e}")

    # Verifică dacă s-a încărcat cel puțin o voce
    if not voices:
        print("AVERTISMENT: Nu s-a putut încărca nicio voce!")
        return [], [], 22050    # Returnează liste goale și rata implicită de eșantionare

    return voices, voice_names, voice_sr   # Returnează vocile, numele și rata de eșantionare

# Funcție pentru încărcarea zgomotelor din setul de date UrbanSound8K
def load_noises_from_urbansound(num_noises=3):
    noises = []       # Lista pentru stocarea semnalelor de zgomot
    noise_names = []  # Lista pentru stocarea numelor zgomotelor

    audio_files = []  # Lista pentru stocarea căilor către fișierele audio
    # Parcurge recursiv toate directoarele pentru a găsi fișierele audio
    for root, dirs, files in os.walk(URBANSOUND_PATH):
        for file in files:
            if file.endswith(('.wav', '.mp3')):  # Verifică dacă fișierul este WAV sau MP3
                audio_files.append(os.path.join(root, file))  # Adaugă calea completă

    print(f"Am găsit {len(audio_files)} fișiere audio în UrbanSound8K")

    # Verifică dacă s-au găsit fișiere audio
    if not audio_files:
        print(f"EROARE: Nu s-au găsit fișiere audio în directorul {URBANSOUND_PATH}")
        return [], [], 22050    # Returnează liste goale și rata implicită de eșantionare

    # Caută fișierul de metadate al setului de date
    metadata_paths = glob.glob(os.path.join(URBANSOUND_PATH, '**/UrbanSound8K.csv'), recursive=True)

    # Dacă există fișierul de metadate, utilizează-l pentru a selecta zgomote specifice
    if metadata_paths:
        import pandas as pd    # Import pentru manipularea datelor tabulare
        metadata_path = metadata_paths[0]
        print(f"Fișier metadata găsit: {metadata_path}")

        try:
            # Încarcă metadatele
            metadata = pd.read_csv(metadata_path)

            # Categorii existente în UrbanSound8K:
            # 0: aer condiționat, 1: claxon, 2: copii jucându-se
            # 3: latrat de câini, 4: exerciții, 5: motor, 6: arme de foc
            # 7: ciocan pneumatic, 8: sirenă, 9: muzică stradală
            # Selectează categorii specifice de zgomote
            categories = [0, 5, 7]  # Aer condiționat, motor, ciocan pneumatic
            category_names = ["Aer condiționat", "Motor", "Ciocan pneumatic"]

            # Procesează fiecare categorie de zgomot
            for i, (category, name) in enumerate(zip(categories, category_names)):
                # Filtrează fișierele după categorie
                category_files = metadata[metadata['classID'] == category]

                if len(category_files) == 0:
                    print(f"Nu există fișiere pentru categoria {name}")
                    continue

                # Selectează aleator un fișier din categoria dorită
                noise_row = category_files.sample(1).iloc[0]
                fold_num = noise_row['fold']         # Numărul fold-ului
                filename = noise_row['slice_file_name']  # Numele fișierului

                # Construiește posibile căi pentru fișier conform structurii UrbanSound8K
                noise_path = None
                possible_paths = [
                    os.path.join(URBANSOUND_PATH, f'audio/fold{fold_num}', filename),
                    os.path.join(URBANSOUND_PATH, f'fold{fold_num}', filename),
                    os.path.join(URBANSOUND_PATH, 'UrbanSound8K', f'audio/fold{fold_num}', filename)
                ]

                # Verifică fiecare cale posibilă
                for path in possible_paths:
                    if os.path.exists(path):
                        noise_path = path
                        break

                # Dacă nu a fost găsit fișierul, caută recursiv în director
                if noise_path is None:
                    for root, dirs, files in os.walk(URBANSOUND_PATH):
                        if filename in files:
                            noise_path = os.path.join(root, filename)
                            break

                # Încarcă fișierul de zgomot dacă a fost găsit
                if noise_path:
                    try:
                        noise, noise_sr = librosa.load(noise_path, sr=None)
                        noise = noise / np.max(np.abs(noise))  # Normalizează semnalul
                        noises.append(noise)
                        noise_names.append(name)
                        print(f"Zgomot încărcat: {name} din {noise_path}")
                    except Exception as e:
                        print(f"Eroare la încărcarea zgomotului: {e}")
                else:
                    print(f"Nu s-a găsit fișier audio pentru {name}")
        except Exception as e:
            print(f"Eroare la procesarea metadatelor: {e}")

    # Dacă nu s-au găsit suficiente zgomote cu metadata, folosește fișiere identificate direct
    while len(noises) < num_noises and audio_files:
        file_path = random.choice(audio_files)
        audio_files.remove(file_path)  # Elimină fișierul din listă pentru a evita duplicatele

        try:
            noise, noise_sr = librosa.load(file_path, sr=None)
            noise = noise / np.max(np.abs(noise))  # Normalizează semnalul
            noises.append(noise)
            noise_names.append(f"Zgomot {len(noises)}")
            print(f"Zgomot încărcat: {file_path}")
        except Exception as e:
            print(f"Eroare la încărcarea zgomotului: {e}")

    # Verifică dacă s-a încărcat cel puțin un zgomot
    if not noises:
        print("AVERTISMENT: Nu s-a putut încărca niciun zgomot!")
        return [], [], 22050    # Returnează liste goale și rata implicită de eșantionare

    return noises, noise_names, noise_sr   # Returnează zgomotele, numele și rata de eșantionare

# Funcție pentru adăugarea zgomotului la voce cu un raport semnal-zgomot (SNR) specificat
def add_noise_to_voice(voice, noise, snr_db=5):
    # Asigură că zgomotul are aceeași lungime ca vocea
    if len(noise) < len(voice):
        # Repetă zgomotul până atinge lungimea vocii
        noise = np.tile(noise, int(np.ceil(len(voice)/len(noise))))[:len(voice)]
    else:
        # Truncheză zgomotul la lungimea vocii
        noise = noise[:len(voice)]

    # Calculează factorul pentru SNR (Signal-to-Noise Ratio)
    voice_power = np.mean(voice**2)      # Puterea medie a semnalului vocal
    noise_power = np.mean(noise**2)      # Puterea medie a zgomotului
    factor = np.sqrt(voice_power / (noise_power * 10**(snr_db/10)))  # Factorul de scalare pentru SNR dorit

    # Adaugă zgomotul scalat la voce
    noisy_voice = voice + factor * noise
    return noisy_voice / np.max(np.abs(noisy_voice))  # Normalizează semnalul rezultat

# Încarcă vocile din LibriSpeech
print("Încărcăm voci din LibriSpeech...")
voices, voice_names, speech_sr = load_voices_from_librispeech(num_voices=3)

# Încarcă zgomotele din UrbanSound8K
print("\nÎncărcăm zgomote din UrbanSound8K...")
noises, noise_names, noise_sr = load_noises_from_urbansound(num_noises=3)

# Verifică dacă au fost încărcate suficiente voci și zgomote
if len(voices) == 0 or len(noises) == 0:
    print("EROARE: Nu s-au putut încărca suficiente voci sau zgomote.")
else:
    # Resample zgomotele la rata de eșantionare a vocilor dacă este necesar
    for i in range(len(noises)):
        if noise_sr != speech_sr:
            print(f"Resample zgomotul {noise_names[i]} de la {noise_sr}Hz la {speech_sr}Hz...")
            noises[i] = librosa.resample(noises[i], orig_sr=noise_sr, target_sr=speech_sr)

    # Creează combinațiile de voce + zgomot
    snr_db = 5  # Raportul semnal-zgomot în dB (se poate ajusta)
    noisy_voices = []    # Lista pentru vocile cu zgomot adăugat
    combination_names = []  # Lista pentru numele combinațiilor

    # Determină numărul de combinații (minim dintre numărul de voci și zgomote)
    num_combinations = min(len(voices), len(noises))
    for i in range(num_combinations):
        voice = voices[i]
        voice_name = voice_names[i]
        noise = noises[i]
        noise_name = noise_names[i]

        print(f"Combinație {i+1}: {voice_name} + {noise_name}")
        # Adaugă zgomotul la voce cu SNR specificat
        noisy_voice = add_noise_to_voice(voice, noise, snr_db)
        noisy_voices.append(noisy_voice)
        combination_names.append(f"{voice_name} + {noise_name}")

    # Afișează semnalele audio în notebook (vocile originale)
    print("\n--- VOCI ORIGINALE ---")
    for i in range(num_combinations):
        print(f"\n{voice_names[i]}:")
        display(Audio(voices[i], rate=speech_sr))

    # Afișează semnalele audio în notebook (zgomotele originale)
    print("\n--- ZGOMOTE ORIGINALE ---")
    for i in range(num_combinations):
        print(f"\n{noise_names[i]}:")
        display(Audio(noises[i], rate=speech_sr))

    # Afișează semnalele audio în notebook (combinațiile)
    print("\n--- COMBINAȚII VOCE + ZGOMOT ---")
    for i in range(num_combinations):
        print(f"\n{combination_names[i]}:")
        display(Audio(noisy_voices[i], rate=speech_sr))

    # Vizualizează formele de undă pentru voci și zgomote
    plt.figure(figsize=(15, 12))  # Creează o figură de dimensiune mare

    # Pentru fiecare combinație, afișează forma de undă a vocii și zgomotului
    for i in range(num_combinations):
        # Forma de undă pentru voce
        plt.subplot(num_combinations, 2, i*2+1)  # Creează un subplot pentru voce
        plt.title(f"Voce: {voice_names[i]}")
        librosa.display.waveshow(voices[i], sr=speech_sr)  # Afișează forma de undă
        plt.xlabel("Timp (s)")
        plt.ylabel("Amplitudine")

        # Forma de undă pentru zgomot
        plt.subplot(num_combinations, 2, i*2+2)  # Creează un subplot pentru zgomot
        plt.title(f"Zgomot: {noise_names[i]}")
        display_length = min(len(noises[i]), len(voices[i]))  # Asigură aceeași lungime pentru comparație
        librosa.display.waveshow(noises[i][:display_length], sr=speech_sr)  # Afișează forma de undă
        plt.xlabel("Timp (s)")
        plt.ylabel("Amplitudine")

    plt.tight_layout()  # Ajustează spațierea între subploturi
    plt.show()  # Afișează figura

    # Vizualizează spectrogramele pentru toate combinațiile voce + zgomot
    plt.figure(figsize=(15, 5*num_combinations))  # Creează o figură de dimensiune mare

    # Pentru fiecare combinație, afișează spectrograma
    for i in range(num_combinations):
        plt.subplot(num_combinations, 1, i+1)  # Creează un subplot
        plt.title(f"Spectrogramă: {combination_names[i]}")
        # Calculează și convertește spectrograma la decibeli
        D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy_voices[i])), ref=np.max)
        # Afișează spectrograma
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')
        plt.colorbar(format='%+2.0f dB')  # Adaugă bara de culori

    plt.tight_layout()  # Ajustează spațierea între subploturi
    plt.show()  # Afișează figura

# Metoda 1: Filtrul Wiener - definește o funcție pentru aplicarea filtrului Wiener
def apply_wiener(noisy_signal):
    return signal.wiener(noisy_signal, mysize=1024)  # Aplică filtrul Wiener cu o fereastră de 1024 de eșantioane

# Verifică dacă variabila noisy_voices există și conține date
if 'noisy_voices' in locals() and len(noisy_voices) > 0:
    # Inițializează o listă goală pentru stocarea rezultatelor filtrării
    wiener_outputs = []

    # Iterează prin fiecare semnal zgomotos și numele său
    for i, (noisy_voice, name) in enumerate(zip(noisy_voices, combination_names)):
        print(f"\n--- Aplicăm filtrul Wiener pentru {name} ---")

        # Aplică filtrul Wiener semnalului zgomotos
        wiener_output = apply_wiener(noisy_voice)
        wiener_outputs.append(wiener_output)  # Adaugă rezultatul în lista de ieșiri

        # Afișează rezultatul audio pentru ascultare
        print(f"Rezultatul filtrului Wiener pentru {name}:")
        display(Audio(wiener_output, rate=speech_sr))

        # Creează o nouă figură pentru vizualizare
        plt.figure(figsize=(12, 8))

        # Prima secțiune: Spectrograma semnalului zgomotos original
        plt.subplot(2, 1, 1)
        plt.title(f"Spectrograma semnalului zgomotos: {name}")
        D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy_voice)), ref=np.max)  # Calculează spectrograma în dB
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')  # Afișează spectrograma
        plt.colorbar(format='%+2.0f dB')  # Adaugă o bară de culoare

        # A doua secțiune: Spectrograma după aplicarea filtrului Wiener
        plt.subplot(2, 1, 2)
        plt.title(f"Spectrograma după filtrul Wiener: {name}")
        D = librosa.amplitude_to_db(np.abs(librosa.stft(wiener_output)), ref=np.max)  # Calculează spectrograma în dB
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')  # Afișează spectrograma
        plt.colorbar(format='%+2.0f dB')  # Adaugă o bară de culoare

        # Ajustează aspectul și afișează figura
        plt.tight_layout()
        plt.show()

    # Creează o figură nouă pentru a compara toate ieșirile filtrului Wiener
    plt.figure(figsize=(15, 10))

    # Afișează spectrogramele pentru toate ieșirile Wiener într-o singură figură
    for i, (wiener_output, name) in enumerate(zip(wiener_outputs, combination_names)):
        plt.subplot(3, 1, i+1)  # Creează un subplot pentru fiecare combinație
        plt.title(f"Spectrograma după filtrul Wiener: {name}")
        D = librosa.amplitude_to_db(np.abs(librosa.stft(wiener_output)), ref=np.max)  # Calculează spectrograma în dB
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')  # Afișează spectrograma
        plt.colorbar(format='%+2.0f dB')  # Adaugă o bară de culoare

    # Ajustează aspectul și afișează figura
    plt.tight_layout()
    plt.show()

    # Definește o funcție pentru calcularea raportului semnal-zgomot (SNR)
    def calculate_snr(clean, processed):
        noise = clean - processed  # Calculează zgomotul ca diferența dintre semnalul curat și cel procesat
        signal_power = np.mean(clean**2)  # Calculează puterea semnalului curat
        noise_power = np.mean(noise**2)  # Calculează puterea zgomotului
        if noise_power == 0:  # Evită împărțirea la zero
            return float('inf')
        return 10 * np.log10(signal_power / noise_power)  # Formulă standard pentru SNR în dB

    # Afișează comparația SNR între semnalele originale și cele filtrate
    print("\n--- Comparație SNR pentru filtrul Wiener ---")
    for i in range(len(voices)):
        original_snr = calculate_snr(voices[i], noisy_voices[i])  # Calculează SNR pentru semnalul zgomotos
        wiener_snr = calculate_snr(voices[i], wiener_outputs[i])  # Calculează SNR pentru semnalul filtrat
        improvement = wiener_snr - original_snr  # Calculează îmbunătățirea SNR

        # Afișează rezultatele
        print(f"Combinația {i+1} ({combination_names[i]}):")
        print(f"  SNR inițial: {original_snr:.2f} dB")
        print(f"  SNR după Wiener: {wiener_snr:.2f} dB")
        print(f"  Îmbunătățire: {improvement:.2f} dB")
else:
    # Afișează un mesaj de eroare dacă nu s-au găsit datele necesare
    print("EROARE: Nu s-au găsit combinațiile de voce și zgomot. Rulați mai întâi codul pentru generarea acestora.")

from sklearn.decomposition import FastICA  # Importăm implementarea ICA din scikit-learn
from scipy import signal  # Importăm modulul signal din scipy pentru procesarea semnalelor
import numpy as np  # Importăm numpy pentru operații numerice

def apply_ica(noisy_signal, delays=[5]):
    """
    Aplică ICA standard și returnează rezultatele.

    Varianta:
    1. ICA standard - selectăm prima componentă
    """
    results = []  # Inițializăm lista pentru stocarea rezultatelor

    for delay in delays:  # Iterăm prin fiecare valoare de întârziere specificată
        # Creăm matricea de observații (original + decalat)
        X = np.zeros((len(noisy_signal), 2))  # Inițializăm matricea cu zerouri
        X[:, 0] = noisy_signal  # Prima coloană este semnalul original
        X[delay:, 1] = noisy_signal[:-delay]  # A doua coloană este semnalul decalat

        # Aplicăm ICA
        ica = FastICA(n_components=2, random_state=42, max_iter=1000)  # Configurăm algoritmul ICA
        sources = ica.fit_transform(X)  # Aplicăm ICA pentru a obține sursele estimate

        # Varianta 1: Prima componentă (abordarea standard)
        ica_output = sources[:, 0]  # Selectăm prima componentă independentă
        ica_output = ica_output / np.max(np.abs(ica_output))  # Normalizăm semnalul rezultat

        results.append({  # Adăugăm rezultatul la lista de rezultate
            'delay': delay,  # Salvăm valoarea întârzierii
            'output': ica_output  # Salvăm semnalul procesat
        })

    return results  # Returnăm toate rezultatele

# Verificăm dacă avem combinațiile generate
if 'noisy_voices' in locals() and len(noisy_voices) > 0:  # Verificăm existența semnalelor zgomotoase
    # Pentru fiecare combinație, aplicăm ICA
    ica_results = []  # Lista pentru toate rezultatele ICA
    best_variants = []  # Lista pentru cele mai bune variante

    for i, (noisy_voice, name) in enumerate(zip(noisy_voices, combination_names)):  # Iterăm prin fiecare semnal zgomotos
        print(f"\n--- Aplicăm ICA pentru {name} ---")  # Afișăm un mesaj informativ

        # Aplicăm ICA cu diferite delay-uri
        variants = apply_ica(noisy_voice, delays=[3, 5, 7])  # Testăm trei valori diferite de întârziere

        # Determinăm cea mai bună variantă pentru această combinație
        best_snr = -float('inf')  # Inițializăm cu cel mai mic SNR posibil
        best_output = None  # Inițializăm output-ul optim cu None
        best_description = ""  # Inițializăm descrierea variantei optime

        # Dacă avem semnalul original, calculăm SNR pentru fiecare variantă
        if 'voices' in locals() and i < len(voices):  # Verificăm dacă avem semnalul vocal original
            clean = voices[i]  # Obținem semnalul vocal original

            for variant_data in variants:  # Iterăm prin toate variantele generate
                delay = variant_data['delay']  # Obținem valoarea întârzierii
                output = variant_data['output']  # Obținem semnalul procesat

                min_len = min(len(clean), len(output))  # Determinăm lungimea minimă pentru comparație
                noise = clean[:min_len] - output[:min_len]  # Calculăm diferența (zgomotul estimat)
                signal_power = np.mean(clean[:min_len]**2)  # Calculăm puterea semnalului original
                noise_power = np.mean(noise**2)  # Calculăm puterea zgomotului estimat
                if noise_power > 0:  # Evităm împărțirea la zero
                    snr = 10 * np.log10(signal_power / noise_power)  # Calculăm SNR în dB
                    if snr > best_snr:  # Dacă acest SNR este mai bun decât cel mai bun de până acum
                        best_snr = snr  # Actualizăm cel mai bun SNR
                        best_output = output  # Actualizăm cel mai bun output
                        best_description = f"ICA (delay={delay})"  # Actualizăm descrierea
        else:
            # Dacă nu avem semnalul original, folosim varianta implicită
            best_output = variants[0]['output']  # Folosim prima variantă
            best_description = "ICA (delay=3)"  # Descrierea implicită

        ica_results.append(variants)  # Adăugăm toate variantele la rezultatele ICA
        best_variants.append({  # Adăugăm cea mai bună variantă la lista
            'output': best_output,
            'description': best_description
        })

        print(f"Cea mai bună variantă pentru {name}: {best_description}")  # Afișăm informații despre cea mai bună variantă

        # Afișăm rezultatul audio pentru cea mai bună variantă
        print(f"Rezultatul pentru {name}:")
        display(Audio(best_output, rate=speech_sr))  # Redăm semnalul audio

        # Afișăm spectrogramele pentru semnalul zgomotos și rezultatul ICA
        plt.figure(figsize=(15, 8))  # Creăm o figură nouă

        plt.subplot(2, 1, 1)  # Prima subplotare
        plt.title(f"Spectrograma semnalului zgomotos: {name}")  # Titlul primei subplotări
        D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy_voice)), ref=np.max)  # Calculăm spectrograma semnalului zgomotos
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')  # Afișăm spectrograma
        plt.colorbar(format='%+2.0f dB')  # Adăugăm bara de culori

        plt.subplot(2, 1, 2)  # A doua subplotare
        plt.title(f"ICA - Rezultat: {name}")  # Titlul celei de-a doua subplotări
        D = librosa.amplitude_to_db(np.abs(librosa.stft(best_output)), ref=np.max)  # Calculăm spectrograma rezultatului ICA
        librosa.display.specshow(D, sr=speech_sr, x_axis='time', y_axis='log')  # Afișăm spectrograma
        plt.colorbar(format='%+2.0f dB')  # Adăugăm bara de culori

        plt.tight_layout()  # Ajustăm aspectul
        plt.show()  # Afișăm figura

    # Calculăm și afișăm SNR pentru a compara rezultatele
    if 'voices' in locals() and len(voices) > 0:  # Verificăm dacă avem semnalele vocale originale
        print("\n--- Comparație SNR pentru ICA ---")  # Afișăm un titlu

        def calculate_snr(clean, processed):  # Definim o funcție pentru calculul SNR
            min_len = min(len(clean), len(processed))  # Determinăm lungimea minimă pentru comparație
            clean = clean[:min_len]  # Trunchiez semnalul original
            processed = processed[:min_len]  # Trunchiez semnalul procesat
            noise = clean - processed  # Calculez diferența (zgomotul estimat)
            signal_power = np.mean(clean**2)  # Calculez puterea semnalului original
            noise_power = np.mean(noise**2)  # Calculez puterea zgomotului estimat
            if noise_power == 0:  # Evităm împărțirea la zero
                return float('inf')  # Returnăm infinit dacă nu există zgomot
            return 10 * np.log10(signal_power / noise_power)  # Calculăm SNR în dB

        for i in range(min(len(voices), len(noisy_voices))):  # Iterăm prin toate exemplele disponibile
            original_snr = calculate_snr(voices[i], noisy_voices[i])  # Calculăm SNR inițial
            best_ica_snr = calculate_snr(voices[i], best_variants[i]['output'])  # Calculăm SNR pentru rezultatul ICA
            improvement = best_ica_snr - original_snr  # Calculăm îmbunătățirea

            print(f"Combinația {i+1} ({combination_names[i]}):")  # Afișăm numele combinației
            print(f"  SNR inițial: {original_snr:.2f} dB")  # Afișăm SNR inițial
            print(f"  SNR după {best_variants[i]['description']}: {best_ica_snr:.2f} dB")  # Afișăm SNR după ICA
            print(f"  Îmbunătățire: {improvement:.2f} dB")  # Afișăm îmbunătățirea SNR

            # Dacă avem și rezultatele Wiener, le comparăm
            if 'wiener_outputs' in locals() and i < len(wiener_outputs):  # Verificăm dacă avem rezultate Wiener
                wiener_snr = calculate_snr(voices[i], wiener_outputs[i])  # Calculăm SNR pentru Wiener
                wiener_improvement = wiener_snr - original_snr  # Calculăm îmbunătățirea pentru Wiener
                print(f"  SNR după Wiener: {wiener_snr:.2f} dB (îmbunătățire: {wiener_improvement:.2f} dB)")  # Afișăm SNR pentru Wiener

                if wiener_snr > best_ica_snr:  # Dacă Wiener are SNR mai bun
                    print(f"  Metoda mai bună: Filtrul Wiener")  # Afișăm că Wiener este mai bun
                elif best_ica_snr > wiener_snr:  # Dacă ICA are SNR mai bun
                    print(f"  Metoda mai bună: {best_variants[i]['description']}")  # Afișăm că ICA este mai bun
                else:
                    print(f"  Performanță similară pentru ambele metode")  # Afișăm că sunt similare
else:
    print("EROARE: Nu s-au găsit combinațiile de voce și zgomot. Rulați mai întâi codul pentru generarea acestora.")  # Afișăm un mesaj de eroare

import os
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
import soundfile as sf
import pandas as pd
from IPython.display import Audio, display
from scipy.signal import butter, filtfilt

# Configurări
SAMPLE_RATE = 16000
SNR_LEVELS = [5, 10]
BASE_DIR = "/content/LibriSpeech"

# Funcții pentru adăugarea zgomotului și denoising
def add_noise_with_snr(clean, noise, snr_db):
    """Adaugă zgomot la semnalul curat cu SNR specific"""
    if len(noise) < len(clean):
        noise = np.tile(noise, int(np.ceil(len(clean)/len(noise))))[:len(clean)]

    clean_power = np.mean(clean**2)
    noise_power = np.mean(noise**2)
    factor = np.sqrt(clean_power / (noise_power * 10**(snr_db / 10)))

    noisy = clean + factor * noise
    return noisy / np.max(np.abs(noisy))

def apply_lowpass_filter(audio, cutoff_freq=3000):
    """Filtru trece-jos pentru reducerea zgomotului de înaltă frecvență"""
    nyq = 0.5 * SAMPLE_RATE
    normal_cutoff = cutoff_freq / nyq
    b, a = butter(3, normal_cutoff, btype='low', analog=False)
    filtered_audio = filtfilt(b, a, audio)
    return filtered_audio

def apply_noise_gate(audio, threshold=0.01, reduction=0.05):
    """Noise gate pentru reducerea zgomotului în zonele cu energie scăzută"""
    energy = np.abs(audio)
    mask = energy < threshold
    gated_audio = audio.copy()
    gated_audio[mask] *= reduction
    return gated_audio

def apply_denoising(noisy):
    """Aplică metoda de denoising"""
    filtered = apply_lowpass_filter(noisy, cutoff_freq=3000)
    result = apply_noise_gate(filtered, threshold=0.015, reduction=0.05)
    result = result / np.max(np.abs(result)) * 0.9
    return result

def calculate_metrics(clean, processed):
    """Calculează metricile de evaluare"""
    # SNR
    noise = processed - clean
    signal_power = np.mean(clean**2)
    noise_power = np.mean(noise**2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else np.inf

    # MSE
    mse = np.mean((clean - processed)**2)

    return snr, mse

def process_and_compare():
    """Funcția principală pentru compararea SNR-urilor"""
    print("Comparație între SNR 5dB și 10dB cu denoising")

    # Găsim toate fișierele .flac
    flac_files = []
    for root, _, files_list in os.walk(BASE_DIR):
        for file in files_list:
            if file.endswith('.flac'):
                flac_files.append(os.path.join(root, file))

    if not flac_files:
        print("Nu s-au găsit fișiere FLAC!")
        return

    print(f"S-au găsit {len(flac_files)} fișiere .flac")

    # Procesăm primul fișier pentru demonstrație vizuală
    results = []

    for i, flac_file in enumerate(flac_files[:5]):  # Limităm la primele 5 fișiere pentru eficiență
        print(f"\nProcesare: {i+1}/5 - {os.path.basename(flac_file)}")

        # Încărcăm fișierul audio
        clean_voice, _ = librosa.load(flac_file, sr=SAMPLE_RATE)

        # Limităm la 5 secunde
        if len(clean_voice) > 5 * SAMPLE_RATE:
            clean_voice = clean_voice[:5 * SAMPLE_RATE]

        # Normalizăm semnalul curat
        clean_voice = clean_voice / np.max(np.abs(clean_voice))

        # Pentru primul fișier, creăm graficul comparativ cu forme de undă
        if i == 0:
            # Generăm zgomot pentru ambele SNR-uri
            noise_5db = np.random.normal(0, 1, len(clean_voice))
            noise_10db = np.random.normal(0, 1, len(clean_voice))

            noisy_voice_5db = add_noise_with_snr(clean_voice, noise_5db, 5)
            noisy_voice_10db = add_noise_with_snr(clean_voice, noise_10db, 10)

            # Creăm graficul comparativ
            plt.figure(figsize=(15, 6))

            samples = SAMPLE_RATE  # 1 secundă
            time_axis = np.arange(samples)

            plt.plot(time_axis, clean_voice[:samples], 'green', label='Original', linewidth=2)
            plt.plot(time_axis, noisy_voice_5db[:samples], 'orange', label='Zgomotos SNR 5dB', alpha=0.8)
            plt.plot(time_axis, noisy_voice_10db[:samples], 'red', label='Zgomotos SNR 10dB', alpha=0.8)

            plt.title('Comparație forme de undă cu zgomot')
            plt.xlabel('Eșantioane')
            plt.ylabel('Amplitudine')
            plt.ylim(-1.1, 1.1)
            plt.grid(True)
            plt.legend()
            plt.tight_layout()
            plt.savefig('/content/comparatie_forme_unda_cu_zgomot.png')
            plt.show()

        # Procesăm pentru fiecare nivel SNR
        for snr in SNR_LEVELS:
            # Generăm zgomot
            noise = np.random.normal(0, 1, len(clean_voice))

            # Adăugăm zgomotul cu SNR specificat
            noisy_voice = add_noise_with_snr(clean_voice, noise, snr)

            # Aplicăm denoising
            denoised_voice = apply_denoising(noisy_voice)

            # Calculăm metricile
            snr_before, mse_before = calculate_metrics(clean_voice, noisy_voice)
            snr_after, mse_after = calculate_metrics(clean_voice, denoised_voice)

            results.append({
                "Fișier": os.path.basename(flac_file),
                "SNR Target": snr,
                "SNR Înainte": round(snr_before, 2),
                "SNR După": round(snr_after, 2),
                "MSE Înainte": round(mse_before, 6),
                "MSE După": round(mse_after, 6),
                "Îmbunătățire SNR": round(snr_after - snr_before, 2)
            })

            # Salvăm fișierele audio
            sf.write(f"/content/{os.path.basename(flac_file).replace('.flac', '')}_snr{snr}dB_noisy.wav",
                     noisy_voice, SAMPLE_RATE)
            sf.write(f"/content/{os.path.basename(flac_file).replace('.flac', '')}_snr{snr}dB_denoised.wav",
                     denoised_voice, SAMPLE_RATE)

            # Vizualizare pentru primul fișier
            if i == 0:
                plt.figure(figsize=(15, 10))

                # Forma de undă
                plt.subplot(3, 2, 1)
                plt.title("Forma de undă - Original")
                plt.plot(clean_voice[:SAMPLE_RATE])
                plt.grid(True)

                plt.subplot(3, 2, 3)
                plt.title(f"Forma de undă - Zgomotos (SNR {snr} dB)")
                plt.plot(noisy_voice[:SAMPLE_RATE])
                plt.grid(True)

                plt.subplot(3, 2, 5)
                plt.title(f"Forma de undă - Denoised (SNR {snr} dB)")
                plt.plot(denoised_voice[:SAMPLE_RATE])
                plt.grid(True)

                # Spectrograme
                plt.subplot(3, 2, 2)
                plt.title("Spectrogramă - Original")
                D = librosa.amplitude_to_db(np.abs(librosa.stft(clean_voice)), ref=np.max)
                librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
                plt.colorbar(format='%+2.0f dB')

                plt.subplot(3, 2, 4)
                plt.title(f"Spectrogramă - Zgomotos (SNR {snr} dB)")
                D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy_voice)), ref=np.max)
                librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
                plt.colorbar(format='%+2.0f dB')

                plt.subplot(3, 2, 6)
                plt.title(f"Spectrogramă - Denoised (SNR {snr} dB)")
                D = librosa.amplitude_to_db(np.abs(librosa.stft(denoised_voice)), ref=np.max)
                librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
                plt.colorbar(format='%+2.0f dB')

                plt.tight_layout()
                plt.savefig(f'/content/comparison_snr{snr}dB.png')
                plt.show()

                # Redare audio
                print(f"\nAudio pentru {os.path.basename(flac_file)} - SNR {snr}dB:")
                print("Original:")
                display(Audio(clean_voice, rate=SAMPLE_RATE))
                print("Zgomotos:")
                display(Audio(noisy_voice, rate=SAMPLE_RATE))
                print("Denoised:")
                display(Audio(denoised_voice, rate=SAMPLE_RATE))

    # Creăm DataFrame cu rezultatele
    df = pd.DataFrame(results)
    df.to_csv("/content/snr_comparison_results.csv", index=False)

    # Comparație vizuală între SNR 5dB și 10dB
    plt.figure(figsize=(12, 8))

    # Îmbunătățire SNR pentru fiecare fișier
    files = df['Fișier'].unique()
    x = np.arange(len(files))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 6))

    snr5_improvements = df[df['SNR Target'] == 5]['Îmbunătățire SNR'].values
    snr10_improvements = df[df['SNR Target'] == 10]['Îmbunătățire SNR'].values

    ax.bar(x - width/2, snr5_improvements, width, label='SNR 5dB')
    ax.bar(x + width/2, snr10_improvements, width, label='SNR 10dB')

    ax.set_xlabel('Fișiere')
    ax.set_ylabel('Îmbunătățire SNR (dB)')
    ax.set_title('Comparație Îmbunătățire SNR: 5dB vs 10dB')
    ax.set_xticks(x)
    ax.set_xticklabels([f.split('.')[0] for f in files], rotation=45, ha='right')
    ax.legend()
    ax.grid(True, axis='y')

    plt.tight_layout()
    plt.savefig('/content/snr_improvement_comparison.png')
    plt.show()

    # Afișăm rezumatul
    print("\n=== REZUMAT COMPARAȚIE ===")
    print(f"Procesate {len(files)} fișiere audio")

    avg_improvement_5db = df[df['SNR Target'] == 5]['Îmbunătățire SNR'].mean()
    avg_improvement_10db = df[df['SNR Target'] == 10]['Îmbunătățire SNR'].mean()

    print(f"Îmbunătățire medie SNR 5dB: {avg_improvement_5db:.2f} dB")
    print(f"Îmbunătățire medie SNR 10dB: {avg_improvement_10db:.2f} dB")

    display(df)

    # Grafic comparativ final
    plt.figure(figsize=(10, 6))
    plt.bar(['SNR 5dB', 'SNR 10dB'], [avg_improvement_5db, avg_improvement_10db], color=['red', 'blue'])
    plt.ylabel('Îmbunătățire medie SNR (dB)')
    plt.title('Comparație Îmbunătățire Medie SNR')
    plt.grid(True, axis='y')
    plt.tight_layout()
    plt.savefig('/content/average_improvement_comparison.png')
    plt.show()

# Rulare funcție principală
if __name__ == "__main__":
    process_and_compare()

from tensorflow.keras.models import Model, save_model, load_model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, LSTM, Flatten, Dense, Reshape
from tensorflow.keras.layers import Dropout, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.metrics import MeanAbsoluteError
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt
import librosa, librosa.display
from IPython.display import Audio, display
import soundfile as sf
import pandas as pd
import os
import tensorflow as tf
import zipfile
import requests
import io
import glob
from tqdm import tqdm
import random
from scipy.signal import butter, filtfilt

# Setări configurabile
SAMPLE_RATE = 16000  # Frecvența de eșantionare standard
SEGMENT_LENGTH = 8192  # Lungimea segmentelor pentru antrenare
ALPHA = 0.8  # Factor pentru mixarea între semnalul original și cel denoised

# Post-procesare
APPLY_NORMALIZATION = True  # Normalizare după procesare
APPLY_POST_FILTER = True    # Aplică filtru lowpass după procesare
POST_FILTER_CUTOFF = 4000   # Frecvența de tăiere pentru filtrul lowpass (Hz)

# Forțează utilizarea CPU pentru a evita erorile de memorie GPU
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# Controlează creșterea memoriei GPU doar când este necesară
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

def download_and_extract_dataset(url, extract_dir):
    """Descarcă și extrage un dataset de pe internet"""
    if not os.path.exists(extract_dir):
        os.makedirs(extract_dir)

    # Verifică dacă datele au fost deja descărcate
    if len(os.listdir(extract_dir)) == 0:
        print(f"Descărcare dataset de la {url}...")
        r = requests.get(url)
        z = zipfile.ZipFile(io.BytesIO(r.content))
        print(f"Extragere în {extract_dir}...")
        z.extractall(extract_dir)
    else:
        print(f"Dataset-ul există deja în {extract_dir}")

def load_librispeech_data(max_files=10):
    """Încarcă date din LibriSpeech pentru voce curată"""
    # URL pentru un subset mic din LibriSpeech
    url = "https://www.openslr.org/resources/12/dev-clean.tar.gz"
    extract_dir = "/content/librispeech"

    # Descărcare și extragere
    if not os.path.exists(extract_dir):
        print("Descărcare și extragere LibriSpeech dev-clean...")
        os.system(f"mkdir -p {extract_dir}")
        os.system(f"wget {url} -O /tmp/librispeech.tar.gz")
        os.system(f"tar -xzf /tmp/librispeech.tar.gz -C {extract_dir}")

    # Găsește toate fișierele .flac
    audio_files = []
    for root, dirs, files in os.walk(extract_dir):
        for file in files:
            if file.endswith(".flac"):
                audio_files.append(os.path.join(root, file))

    # Limitează numărul de fișiere pentru testare
    audio_files = audio_files[:max_files]

    # Încarcă și concatenează datele audio
    clean_data = []
    for file in tqdm(audio_files, desc="Încărcare date LibriSpeech"):
        audio, sr = librosa.load(file, sr=SAMPLE_RATE)
        clean_data.append(audio)

    # Concatenează toate datele audio
    clean_voice = np.concatenate(clean_data)
    print(f"Date LibriSpeech încărcate: {len(clean_voice) / SAMPLE_RATE:.2f} secunde de audio")

    return clean_voice

def load_urbansound_data(max_files=10):
    """Încarcă date din UrbanSound8K pentru zgomot"""

    urbansound_dir = "/content/urbansound"

    # Verifică dacă directorul există și conține fișiere
    if not os.path.exists(urbansound_dir) or len(glob.glob(f"{urbansound_dir}/**/*.wav", recursive=True)) == 0:
        print("UrbanSound8K nu este disponibil. Generând zgomot sintetic...")

        # Generează diferite tipuri de zgomot pentru 30 de secunde
        noise_length = 30 * SAMPLE_RATE
        noise_data = []

        # Zgomot alb
        white_noise = np.random.normal(0, 0.1, noise_length)
        noise_data.append(white_noise)

        # Zgomot roz (filtrat)
        pink_noise = np.random.normal(0, 0.1, noise_length)
        for i in range(1, len(pink_noise)):
            pink_noise[i] = pink_noise[i-1] * 0.9 + pink_noise[i] * 0.1
        noise_data.append(pink_noise * 0.5)  # Normalizare aproximativă

        # Zgomot cu componente de frecvență joasă
        t = np.arange(noise_length) / SAMPLE_RATE
        low_freq_noise = np.sin(2 * np.pi * 50 * t) * 0.1  # 50 Hz component
        low_freq_noise += np.sin(2 * np.pi * 100 * t) * 0.05  # 100 Hz component
        low_freq_noise += np.random.normal(0, 0.05, noise_length)  # Adaugă puțin zgomot aleator
        noise_data.append(low_freq_noise)

        # Concatenează toate zgomotele
        noise = np.concatenate(noise_data)
    else:
        # Încarcă date reale din UrbanSound8K
        audio_files = glob.glob(f"{urbansound_dir}/**/*.wav", recursive=True)
        audio_files = audio_files[:max_files]  # Limitează la max_files

        noise_data = []
        for file in tqdm(audio_files, desc="Încărcare date UrbanSound"):
            audio, sr = librosa.load(file, sr=SAMPLE_RATE)
            noise_data.append(audio)

        # Concatenează zgomotele
        noise = np.concatenate(noise_data)

    print(f"Date de zgomot încărcate: {len(noise) / SAMPLE_RATE:.2f} secunde de audio")
    return noise

def create_noisy_audio(clean_voice, noise, snr_db=10):
    """Creează audio zgomotos combinând vocea curată cu zgomot la un SNR dat"""
    # Asigură-te că ambele semnale sunt normalizate
    clean_voice = clean_voice / np.max(np.abs(clean_voice))
    noise = noise / np.max(np.abs(noise))

    # Asigură-te că zgomotul este cel puțin la fel de lung ca vocea curată
    if len(noise) < len(clean_voice):
        # Repetă zgomotul pentru a acoperi toată lungimea vocii
        num_repeats = int(np.ceil(len(clean_voice) / len(noise)))
        noise = np.tile(noise, num_repeats)

    # Taie zgomotul la aceeași lungime ca vocea
    noise = noise[:len(clean_voice)]

    # Calculează puterile semnalelor
    clean_power = np.mean(clean_voice**2)
    noise_power = np.mean(noise**2)

    # Calculează factorul de scalare pentru zgomot pentru a atinge SNR-ul dorit
    snr_linear = 10**(snr_db/10)
    scaling_factor = np.sqrt(clean_power / (noise_power * snr_linear))

    # Scalează zgomotul și adaugă-l la vocea curată
    scaled_noise = noise * scaling_factor
    noisy_voice = clean_voice + scaled_noise

    # Normalizare finală
    noisy_voice = noisy_voice / np.max(np.abs(noisy_voice))

    return noisy_voice

def create_nn_model(input_shape):

    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv1D(32, 3, padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling1D(pool_size=2)(x)

    x = Conv1D(64, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling1D(pool_size=2)(x)

    # Salvează forma înainte de aplatizare pentru reconstrucție ulterioară
    shape_before_flatten = x.shape[1:]
    x = Flatten()(x)

    # Straturi dense pentru procesare
    x = Dense(256)(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = Dropout(0.2)(x)

    # Ieșire pentru clasificare
    output_classification = Dense(10, activation='softmax', name='classification_output')(x)

    # Reconstrucție pentru decodare
    x = Dense(int(shape_before_flatten[0]) * int(shape_before_flatten[1]), activation='relu')(x)
    x = BatchNormalization()(x)
    x = Reshape(shape_before_flatten)(x)

    # Decoder cu LSTM
    x = LSTM(64, return_sequences=True)(x)

    # Primul strat de upsampling
    x = Conv1D(64, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = UpSampling1D(size=2)(x)

    # Al doilea strat de upsampling
    x = Conv1D(32, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = UpSampling1D(size=2)(x)

    # Strat final pentru denoising
    x = Conv1D(16, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # Output denoiser
    denoising_output = Conv1D(1, 3, padding='same', activation='tanh', name='denoising_output')(x)

    model = Model(inputs, [denoising_output, output_classification])

    # IMPORTANT: Am eliminat 'accuracy' din metricile pentru denoising_output
    # deoarece nu este potrivită pentru o problemă de regresie
    model.compile(
        optimizer=Adam(learning_rate=0.0005),
        loss={
            'denoising_output': 'mse',
            'classification_output': 'sparse_categorical_crossentropy'
        },
        loss_weights={
            'denoising_output': 0.7,
            'classification_output': 0.3
        },
        metrics={
            'denoising_output': [MeanAbsoluteError()],  # Doar MAE, fără accuracy
            'classification_output': ['accuracy']
        }
    )
    return model

def apply_lowpass_filter(audio, cutoff_freq, sample_rate):
    """
    Aplică un filtru trece-jos (lowpass) pentru a elimina frecvențele înalte nedorite
    """
    # Calculează frecvența normalizată Nyquist
    nyq = 0.5 * sample_rate
    normal_cutoff = cutoff_freq / nyq

    # Design filtru Butterworth
    b, a = butter(3, normal_cutoff, btype='low', analog=False)

    # Aplică filtrul
    filtered_audio = filtfilt(b, a, audio)

    return filtered_audio

def apply_noise_gate(audio, threshold=0.01, reduction=0.1):
    """
    Aplică un noise gate pentru a reduce și mai mult zgomotul în zonele cu energie scăzută
    """
    # Calculează energia semnalului
    energy = np.abs(audio)

    # Creează o mască pentru zonele cu energie sub prag
    mask = energy < threshold

    # Aplică reducerea în zonele identificate
    gated_audio = audio.copy()
    gated_audio[mask] *= reduction

    return gated_audio

def apply_nn(noisy, model):
    """
    Aplică modelul cu mixare între original și prelucrat folosind ALPHA
    Îmbunătățit pentru a evita artefactele la marginile segmentelor și cu post-procesare
    """
    segment_length = SEGMENT_LENGTH
    hop = segment_length // 4  # Hop mai mic pentru rezultate mai bune

    # Folosim ferestre Hanning pentru a evita discontinuități
    window = np.hanning(segment_length)

    # Inițializare rezultat și contoare pentru suprapunere
    result = np.zeros(len(noisy) + segment_length)
    overlaps = np.zeros(len(noisy) + segment_length)

    for i in range(0, len(noisy), hop):
        segment = noisy[i:i+segment_length]
        if len(segment) < segment_length:
            segment = np.pad(segment, (0, segment_length - len(segment)))

        segment_input = segment.reshape(1, segment_length, 1)
        outputs = model.predict(segment_input, verbose=0)
        segment_output = outputs[0][0, :, 0]

        # Aplică fereastra Hanning pentru tranziții line
        windowed_output = segment_output * window

        # Mixare între original și processat folosind ALPHA
        mixed_output = ALPHA * windowed_output + (1-ALPHA) * segment * window

        result[i:i+segment_length] += mixed_output
        overlaps[i:i+segment_length] += window

    # Normalizează în funcție de suprapuneri
    mask = overlaps > 0.01  # Evită împărțirea la valori foarte mici
    result[mask] /= overlaps[mask]

    # Taie la lungimea originală
    result = result[:len(noisy)]

    # Aplică normalizare pentru a evita distorsiunile
    if APPLY_NORMALIZATION:
        result = result / np.max(np.abs(result)) * 0.9

    # Aplică un filtru trece-jos (lowpass) pentru a elimina artefactele de înaltă frecvență
    if APPLY_POST_FILTER:
        result = apply_lowpass_filter(result, POST_FILTER_CUTOFF, SAMPLE_RATE)

        # Aplică noise gate pentru a reduce și mai mult zgomotul în zonele cu energie scăzută
        result = apply_noise_gate(result, threshold=0.015, reduction=0.05)

        # Normalizare finală după filtrare
        result = result / np.max(np.abs(result)) * 0.9

    return result

def calculate_snr(clean, processed):
    """Calculează raportul semnal-zgomot (SNR) în dB."""
    min_len = min(len(clean), len(processed))
    clean = clean[:min_len]
    processed = processed[:min_len]

    # Asigură-te că sunt normalizate pentru comparație corectă
    clean = clean / np.max(np.abs(clean))
    processed = processed / np.max(np.abs(processed))

    noise = clean - processed
    signal_power = np.mean(clean**2)
    noise_power = np.mean(noise**2)

    # Evită împărțirea la zero
    if noise_power < 1e-10:
        return 100.0  # Valoare mare pentru SNR foarte bun

    return 10 * np.log10(signal_power / noise_power)

def calculate_accuracy(clean, processed, threshold=0.1):
    """
    Calculează acuratețea ca procent din eșantioane cu eroare sub prag
    """
    min_len = min(len(clean), len(processed))
    clean = clean[:min_len] / np.max(np.abs(clean))
    processed = processed[:min_len] / np.max(np.abs(processed))

    error = np.abs(clean - processed)
    return np.sum(error < threshold) / len(clean) * 100

def evaluate_model(clean, noisy, processed):
    """
    Evaluează modelul calculând metricile de performanță
    și afișând vizualizări comparative
    """
    min_len = min(len(clean), len(noisy), len(processed))
    clean = clean[:min_len]
    noisy = noisy[:min_len]
    processed = processed[:min_len]

    # Normalizare pentru comparație corectă
    clean = clean / np.max(np.abs(clean))
    noisy = noisy / np.max(np.abs(noisy))
    processed = processed / np.max(np.abs(processed))

    # Calculează metricile
    snr_input = calculate_snr(clean, noisy)
    snr_output = calculate_snr(clean, processed)
    accuracy = calculate_accuracy(clean, processed)
    mae = np.mean(np.abs(clean - processed))
    mse = np.mean((clean - processed) ** 2)
    rmse = np.sqrt(mse)

    # Afișează metricile
    print("\n--- METRICI DE PERFORMANȚĂ ---")
    print(f"SNR inițial: {snr_input:.2f} dB")
    print(f"SNR denoised: {snr_output:.2f} dB")
    print(f"Îmbunătățire SNR: {snr_output - snr_input:.2f} dB")
    print(f"Acuratețe: {accuracy:.2f}%")
    print(f"MAE (Mean Absolute Error): {mae:.6f}")
    print(f"MSE (Mean Squared Error): {mse:.6f}")
    print(f"RMSE (Root Mean Squared Error): {rmse:.6f}")

    # Creează un tabel cu metricile pentru afișare
    metrics_df = pd.DataFrame({
        'Metrică': ['SNR inițial (dB)', 'SNR denoised (dB)', 'Îmbunătățire SNR (dB)',
                   'Acuratețe (%)', 'MAE', 'MSE', 'RMSE'],
        'Valoare': [snr_input, snr_output, snr_output - snr_input,
                   accuracy, mae, mse, rmse]
    })

    display(metrics_df)

    # Afișare grafică a metricilor principale
    plt.figure(figsize=(12, 6))
    plt.bar(['MAE', 'MSE', 'RMSE'], [mae, mse, rmse])
    plt.title('Metrici de eroare pentru denoising')
    plt.ylabel('Valoare')
    plt.grid(True, alpha=0.3)
    plt.savefig('/content/error_metrics_final.png')
    plt.show()

    # Afișare comparativă a formelor de undă
    samples = 2000  # Număr de eșantioane pentru vizualizare
    time = np.arange(samples) / SAMPLE_RATE

    plt.figure(figsize=(14, 8))

    plt.subplot(3, 1, 1)
    plt.plot(time, clean[:samples])
    plt.title('Semnal Original')
    plt.ylabel('Amplitudine')
    plt.grid(True)

    plt.subplot(3, 1, 2)
    plt.plot(time, noisy[:samples])
    plt.title('Semnal Zgomotos')
    plt.ylabel('Amplitudine')
    plt.grid(True)

    plt.subplot(3, 1, 3)
    plt.plot(time, processed[:samples])
    plt.title(f'Semnal Denoised (Acuratețe: {accuracy:.2f}%)')
    plt.xlabel('Timp (s)')
    plt.ylabel('Amplitudine')
    plt.grid(True)

    plt.tight_layout()
    plt.savefig('/content/waveform_comparison.png')
    plt.show()

    # Afișare spectrograme pentru comparație
    plt.figure(figsize=(15, 15))

    plt.subplot(3, 1, 1)
    plt.title("Spectrogramă - Original")
    D = librosa.amplitude_to_db(np.abs(librosa.stft(clean)), ref=np.max)
    librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
    plt.colorbar(format='%+2.0f dB')

    plt.subplot(3, 1, 2)
    plt.title("Spectrogramă - Zgomotos")
    D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy)), ref=np.max)
    librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
    plt.colorbar(format='%+2.0f dB')

    plt.subplot(3, 1, 3)
    plt.title(f"Spectrogramă - Denoised (Acc: {accuracy:.2f}%)")
    D = librosa.amplitude_to_db(np.abs(librosa.stft(processed)), ref=np.max)
    librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='log')
    plt.colorbar(format='%+2.0f dB')

    plt.tight_layout()
    plt.savefig('/content/spectrogram_comparison.png')
    plt.show()

    return {
        'snr_input': snr_input,
        'snr_output': snr_output,
        'accuracy': accuracy,
        'mae': mae,
        'mse': mse,
        'rmse': rmse
    }

def plot_training_metrics(history):
    """
    Afișează metricile de antrenare corectate
    """
    plt.figure(figsize=(14, 10))

    # Loss total
    plt.subplot(3, 1, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Total Loss')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Acuratețe clasificare
    if 'classification_output_accuracy' in history.history:
        plt.subplot(3, 1, 2)
        plt.plot(history.history['classification_output_accuracy'], label='Train Class Acc')
        plt.plot(history.history['val_classification_output_accuracy'], label='Val Class Acc')
        plt.title('Classification Accuracy')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True, alpha=0.3)

    # MAE pentru denoising (în loc de acuratețe)
    if 'denoising_output_mean_absolute_error' in history.history:
        plt.subplot(3, 1, 3)
        plt.plot(history.history['denoising_output_mean_absolute_error'],
                 label='Train Denoise MAE')
        plt.plot(history.history['val_denoising_output_mean_absolute_error'],
                 label='Val Denoise MAE')
        plt.title('Denoising Mean Absolute Error')
        plt.xlabel('Epochs')
        plt.ylabel('MAE')
        plt.legend()
        plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("/content/training_metrics.png")
    plt.show()

def augment_data(clean_segment, noisy_segment):
    """
    Augmentează datele prin variații moderate de amplitudine și
    transformări simple pentru a îmbunătăți generalizarea
    """
    # Ajustare de amplitudine moderată
    gain = np.random.uniform(0.9, 1.1)
    clean_aug = clean_segment * gain
    noisy_aug = noisy_segment * gain

    # Evitare clipping
    if np.max(np.abs(clean_aug)) > 0.99:
        clean_aug = clean_aug / np.max(np.abs(clean_aug)) * 0.99
    if np.max(np.abs(noisy_aug)) > 0.99:
        noisy_aug = noisy_aug / np.max(np.abs(noisy_aug)) * 0.99

    # Inversare semnal (50% șansă)
    if np.random.random() < 0.5:
        clean_aug = -clean_aug
        noisy_aug = -noisy_aug

    # Modificare fază (shift temporal mic)
    if np.random.random() < 0.3:
        shift = np.random.randint(1, 20)
        clean_aug = np.roll(clean_aug, shift)
        noisy_aug = np.roll(noisy_aug, shift)

    # În unele cazuri, mixează parțial semnalul curat cu cel zgomotos
    if np.random.random() < 0.3:
        mix_ratio = np.random.uniform(0.7, 0.9)
        mixed_clean = mix_ratio * clean_aug + (1 - mix_ratio) * noisy_aug
        return mixed_clean, noisy_aug

    return clean_aug, noisy_aug

def process_loaded_model(model_path, audio_file, output_file=None):
    """
    Funcție pentru procesarea unui fișier audio cu un model deja antrenat
    """
    # Încarcă modelul
    print(f"Încărcare model din {model_path}...")
    model = load_model(model_path)

    # Încarcă audio
    print(f"Încărcare fișier audio {audio_file}...")
    audio, sr = librosa.load(audio_file, sr=SAMPLE_RATE)

    # Normalizare
    audio = audio / np.max(np.abs(audio))

    # Procesare
    print("Aplicare model pentru denoising...")
    processed_audio = apply_nn(audio, model)

    # Salvare rezultat
    if output_file is not None:
        print(f"Salvare rezultat în {output_file}")
        sf.write(output_file, processed_audio, SAMPLE_RATE)

    print("Afișare audio original și procesat:")
    print("Original:"); display(Audio(audio, rate=SAMPLE_RATE))
    print(f"Denoised (alpha={ALPHA}):"); display(Audio(processed_audio, rate=SAMPLE_RATE))

    return processed_audio

def train_and_evaluate(clean_voice, noisy_voice, speech_sr=SAMPLE_RATE):
    """
    Funcția principală pentru antrenarea și evaluarea modelului
    """
    # Verifică și asigură-te că semnalele au aceeași lungime
    min_len = min(len(clean_voice), len(noisy_voice))
    clean_voice = clean_voice[:min_len]
    noisy_voice = noisy_voice[:min_len]

    # Normalizare pentru antrenare
    clean_voice = clean_voice / np.max(np.abs(clean_voice))
    noisy_voice = noisy_voice / np.max(np.abs(noisy_voice))

    # Verifică valorile pentru a te asigura că sunt normalizate corect
    print(f"Clean voice: min={np.min(clean_voice):.4f}, max={np.max(clean_voice):.4f}")
    print(f"Noisy voice: min={np.min(noisy_voice):.4f}, max={np.max(noisy_voice):.4f}")

    # ANTRENARE
    segment_length = SEGMENT_LENGTH
    X, y_clean, y_classes = [], [], []

    print("Pregătire date de antrenare...")
    step = segment_length // 2  # Pas pentru extragerea segmentelor

    # Extragere segmente cu augmentare
    for i in range(0, len(clean_voice) - segment_length, step):
        # Segment original
        clean_segment = clean_voice[i:i+segment_length]
        noisy_segment = noisy_voice[i:i+segment_length]

        # Verifică energia semnalului pentru a sări peste segmente de tăcere
        if np.mean(np.abs(clean_segment)) > 0.01:
            X.append(noisy_segment.reshape(segment_length, 1))
            y_clean.append(clean_segment.reshape(segment_length, 1))

            # Caracteristică simplă pentru clasificare
            feature = np.mean(np.abs(clean_segment)) * 10
            y_classes.append(min(9, max(0, int(feature))))

            # Augmentare date (pentru 50% din segmente)
            if i % 2 == 1:
                clean_aug, noisy_aug = augment_data(clean_segment, noisy_segment)
                X.append(noisy_aug.reshape(segment_length, 1))
                y_clean.append(clean_aug.reshape(segment_length, 1))
                feature = np.mean(np.abs(clean_aug)) * 10
                y_classes.append(min(9, max(0, int(feature))))

    X, y_clean, y_classes = np.array(X), np.array(y_clean), np.array(y_classes)

    print(f"Forma datelor: X = {X.shape}, y_clean = {y_clean.shape}, y_classes = {y_classes.shape}")

    # Împarte datele pentru antrenare și validare
    X_train, X_val, y_train_clean, y_val_clean, y_train_class, y_val_class = train_test_split(
        X, y_clean, y_classes, test_size=0.2, random_state=42)

    print("Crearea modelului...")
    model = create_nn_model((segment_length, 1))
    model.summary()

    # Parametri de antrenare
    batch_size = 32  # Mărește pentru antrenare mai rapidă
    epochs = 50      # Poți ajusta în funcție de performanță

    # Callbacks pentru antrenare
    callbacks = [
        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),
        ModelCheckpoint('/content/best_model.h5', save_best_only=True, monitor='val_loss')
    ]

    print("Începere antrenare...")
    history = model.fit(
        X_train,
        {'denoising_output': y_train_clean, 'classification_output': y_train_class},
        validation_data=(X_val, {'denoising_output': y_val_clean, 'classification_output': y_val_class}),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=callbacks,
        verbose=1
    )

    # Afișează metricile de antrenare corectate
    plot_training_metrics(history)

    # Salvare model
    print("Salvare model...")
    save_model(model, '/content/model_denoising_final.h5')

    # Aplicarea modelului pe întregul semnal
    print(f"\n--- PROCESARE AUDIO CU ALPHA={ALPHA} ---")
    nn_output = apply_nn(noisy_voice, model)

    # Salvează rezultatul procesat
    sf.write("/content/denoised_output.wav", nn_output, speech_sr)

    # Evaluarea modelului pe semnalul complet
    print("\n--- EVALUARE PE SEMNALUL COMPLET ---")
    metrics = evaluate_model(clean_voice, noisy_voice, nn_output)

    # Afișarea exemplelor audio
    print("Original:"); display(Audio(clean_voice, rate=speech_sr))
    print("Zgomotos:"); display(Audio(noisy_voice, rate=speech_sr))
    print(f"Denoised (alpha={ALPHA}):"); display(Audio(nn_output, rate=speech_sr))

    print("\n--- FINALIZAT ---")
    print(f"Modelul a fost antrenat și aplicat cu succes. Factorul alpha fix este {ALPHA}.")
    print("Rezultatul denoised a fost salvat ca '/content/denoised_output.wav'")
    print(f"SNR îmbunătățit cu {metrics['snr_output'] - metrics['snr_input']:.2f} dB")

    return model, nn_output, metrics

def main():
    """
    Funcția principală care pregătește datele și apelează antrenarea
    """
    print("Încărcare date LibriSpeech pentru voce curată...")
    clean_voice = load_librispeech_data(max_files=5)  # Limitare la 5 fișiere pentru test

    print("Încărcare date UrbanSound pentru zgomot...")
    noise = load_urbansound_data(max_files=5)  # Limitare la 5 fișiere pentru test

    print("Crearea semnalului zgomotos combinat...")
    # Creăm semnale zgomotoase la diferite niveluri SNR
    snr_levels = [15, 10, 5]  # SNR în dB (mai mare = mai puțin zgomot)
    noisy_signals = []

    for snr in snr_levels:
        print(f"Generare semnal zgomotos la SNR = {snr} dB")
        noisy = create_noisy_audio(clean_voice, noise, snr_db=snr)
        noisy_signals.append(noisy)

    # Concatenăm semnalele pentru mai multă diversitate
    noisy_voice = np.concatenate(noisy_signals)

    # Asigură-te că vocile au aceeași lungime
    min_len = min(len(clean_voice), len(noisy_voice))
    clean_voice = np.tile(clean_voice, int(np.ceil(len(noisy_voice) / len(clean_voice))))[:len(noisy_voice)]

    # Salvează semnalele pentru referință
    sf.write("/content/clean_voice.wav", clean_voice, SAMPLE_RATE)
    sf.write("/content/noisy_voice.wav", noisy_voice, SAMPLE_RATE)

    print("Afișare exemple audio pentru verificare:")
    print("Clean:"); display(Audio(clean_voice, rate=SAMPLE_RATE))
    print("Noisy:"); display(Audio(noisy_voice, rate=SAMPLE_RATE))

    # Antrenare și evaluare
    model, denoised_voice, metrics = train_and_evaluate(clean_voice, noisy_voice, SAMPLE_RATE)

    # Salvează setările inițiale
    global APPLY_NORMALIZATION, APPLY_POST_FILTER
    orig_norm = APPLY_NORMALIZATION
    orig_filter = APPLY_POST_FILTER

    # Procesare fără post-procesare
    APPLY_NORMALIZATION = False
    APPLY_POST_FILTER = False
    no_post = apply_nn(noisy_voice, model)
    sf.write("/content/denoised_no_post.wav", no_post, SAMPLE_RATE)

    # Procesare doar cu normalizare
    APPLY_NORMALIZATION = True
    APPLY_POST_FILTER = False
    norm_only = apply_nn(noisy_voice, model)
    sf.write("/content/denoised_norm_only.wav", norm_only, SAMPLE_RATE)

    # Procesare completă (normalizare + filtru)
    APPLY_NORMALIZATION = True
    APPLY_POST_FILTER = True
    full_post = apply_nn(noisy_voice, model)
    sf.write("/content/denoised_full_post.wav", full_post, SAMPLE_RATE)

    # Afișare pentru comparație
    print("Fără post-procesare:"); display(Audio(no_post, rate=SAMPLE_RATE))
    print("Doar normalizare:"); display(Audio(norm_only, rate=SAMPLE_RATE))
    print("Normalizare + Filtru:"); display(Audio(full_post, rate=SAMPLE_RATE))

    # Restaurare setări
    APPLY_NORMALIZATION = orig_norm
    APPLY_POST_FILTER = orig_filter

    return model, clean_voice, noisy_voice, denoised_voice, metrics

if __name__ == "__main__":
    main()

# Definește o funcție pentru procesarea unui fișier audio încărcat de utilizator
def process_user_audio():
    from google.colab import files  # Importă modulul pentru încărcarea fișierelor în Colab
    from sklearn.decomposition import FastICA  # Importă algoritmul ICA pentru separarea surselor
    from scipy import signal  # Importă funcții pentru procesarea semnalelor
    from tensorflow.keras.models import Model  # Importă clasa Model din Keras
    from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, LSTM  # Importă straturi pentru rețeaua neurală
    from tensorflow.keras.optimizers import Adam  # Importă optimizatorul Adam
    from tensorflow.keras.callbacks import EarlyStopping  # Importă callback pentru oprire prematură

    print("Încarcă un fișier audio zgomotos:")  # Afișează un mesaj pentru utilizator
    uploaded = files.upload()  # Deschide dialogul pentru încărcare de fișiere

    if not uploaded:  # Verifică dacă utilizatorul a încărcat vreun fișier
        print("Niciun fișier încărcat.")  # Afișează un mesaj dacă nu s-a încărcat nimic
        return  # Încheie funcția

    filename = list(uploaded.keys())[0]  # Obține numele primului fișier încărcat
    noisy, sr = librosa.load(filename, sr=None)  # Încarcă fișierul audio cu rata de eșantionare originală
    noisy = noisy / np.max(np.abs(noisy))  # Normalizează semnalul audio între -1 și 1

    print(f"Fișier încărcat: {filename}, durata: {len(noisy)/sr:.2f} secunde")  # Afișează informații despre fișier

    print("Fișierul audio original (zgomotos):")  # Afișează un titlu pentru audio-ul original
    display(Audio(noisy, rate=sr))  # Afișează un player audio cu semnalul zgomotos

    # Metoda 1: Filtrul Wiener
    print("\n1. Aplicăm filtrul Wiener...")  # Afișează un mesaj despre aplicarea filtrului Wiener
    wiener_output = signal.wiener(noisy, mysize=1024)  # Aplică filtrul Wiener cu o fereastră de 1024

    # Metoda 2: ICA cu delay=5
    print("2. Aplicăm ICA...")  # Afișează un mesaj despre aplicarea ICA
    def apply_ica(noisy_signal, delay=5):  # Definește o funcție pentru aplicarea ICA
        X = np.zeros((len(noisy_signal), 2))  # Creează o matrice pentru observații
        X[:, 0] = noisy_signal  # Prima coloană este semnalul original
        X[delay:, 1] = noisy_signal[:-delay]  # A doua coloană este semnalul decalat

        ica = FastICA(n_components=2, random_state=42, max_iter=1000)  # Inițializează algoritmul ICA
        sources = ica.fit_transform(X)  # Aplică ICA pentru a obține sursele estimate

        ica_output = sources[:, 0]  # Selectează prima componentă estimată
        return ica_output / np.max(np.abs(ica_output))  # Normalizează și returnează rezultatul

    ica_output = apply_ica(noisy)  # Aplică funcția ICA semnalului zgomotos

    # Metoda 3: Rețea Neuronală cu 50 epoci
    print("3. Antrenăm și aplicăm rețeaua neuronală (50 epoci)...")  # Afișează un mesaj despre antrenarea rețelei
    def create_nn_model(input_shape):  # Definește o funcție pentru crearea modelului neural
        inputs = Input(shape=input_shape)  # Definește stratul de intrare

        # Encoder - partea de codificare a modelului
        x = Conv1D(16, 3, padding='same', activation='relu')(inputs)  # Primul strat convoluțional
        x = MaxPooling1D(pool_size=2)(x)  # Strat de pooling pentru reducerea dimensionalității
        x = Conv1D(32, 3, padding='same', activation='relu')(x)  # Al doilea strat convoluțional
        x = MaxPooling1D(pool_size=2)(x)  # Al doilea strat de pooling

        # Procesare - strat recurrent
        x = LSTM(64, return_sequences=True)(x)  # Strat LSTM pentru captarea dependențelor temporale

        # Decoder - partea de decodificare a modelului
        x = Conv1D(32, 3, padding='same', activation='relu')(x)  # Primul strat convoluțional în decoder
        x = UpSampling1D(size=2)(x)  # Primul strat de upsampling
        x = Conv1D(16, 3, padding='same', activation='relu')(x)  # Al doilea strat convoluțional în decoder
        x = UpSampling1D(size=2)(x)  # Al doilea strat de upsampling

        # Ieșire - strat final
        outputs = Conv1D(1, 3, padding='same', activation='tanh')(x)  # Strat de ieșire cu activare tanh

        model = Model(inputs, outputs)  # Creează modelul
        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')  # Compilează modelul cu optimizator Adam și loss MSE
        return model  # Returnează modelul

    def train_nn(clean, noisy, epochs=100):  # Definește o funcție pentru antrenarea modelului
        segment_length = 8192  # Definește lungimea segmentelor pentru antrenare
        X_train = []  # Inițializează lista pentru datele de intrare
        y_train = []  # Inițializează lista pentru datele țintă

        for i in range(0, len(clean)-segment_length, segment_length//2):  # Iterează prin semnal cu suprapunere
            X_train.append(noisy[i:i+segment_length].reshape(segment_length, 1))  # Adaugă segment zgomotos
            y_train.append(clean[i:i+segment_length].reshape(segment_length, 1))  # Adaugă segment curat

        X_train = np.array(X_train)  # Convertește lista la array NumPy
        y_train = np.array(y_train)  # Convertește lista la array NumPy

        print(f"Date de antrenare: {len(X_train)} segmente")  # Afișează numărul de segmente

        model = create_nn_model((segment_length, 1))  # Creează modelul neural

        early_stopping = EarlyStopping(  # Configurează callback pentru oprire prematură
            monitor='loss',  # Monitorizează loss-ul
            patience=5,  # Numărul de epoci fără îmbunătățire înainte de oprire
            restore_best_weights=True,  # Restaurează cele mai bune ponderi
            verbose=1  # Nivel de detalii în output
        )

        model.fit(  # Antrenează modelul
            X_train, y_train,  # Date de intrare și țintă
            epochs=epochs,  # Numărul maxim de epoci
            batch_size=32,  # Mărimea batch-ului
            callbacks=[early_stopping],  # Lista de callbacks
            verbose=1  # Nivel de detalii în output
        )

        return model  # Returnează modelul antrenat

    def apply_nn(noisy, model):  # Definește o funcție pentru aplicarea modelului antrenat
        segment_length = 8192  # Definește lungimea segmentelor pentru procesare
        result = np.zeros_like(noisy)  # Inițializează array-ul rezultat cu zero

        for i in range(0, len(noisy)-segment_length, segment_length//2):  # Iterează prin semnal cu suprapunere
            segment = noisy[i:i+segment_length]  # Extrage un segment
            if len(segment) < segment_length:  # Verifică dacă segmentul e mai scurt decât dimensiunea necesară
                segment = np.pad(segment, (0, segment_length-len(segment)))  # Completează cu zero

            segment_input = segment.reshape(1, segment_length, 1)  # Reshape pentru model
            segment_output = model.predict(segment_input, verbose=0)[0, :, 0]  # Aplică modelul și extrage rezultatul

            if i == 0:  # Dacă e primul segment
                result[i:i+segment_length] = segment_output  # Copiază direct rezultatul
            else:  # Pentru restul segmentelor
                overlap = segment_length//2  # Calculează suprapunerea
                fade_in = np.linspace(0, 1, overlap)  # Creează vector pentru fade in
                fade_out = np.linspace(1, 0, overlap)  # Creează vector pentru fade out

                # Aplică crossfade în zona de suprapunere
                result[i:i+overlap] = result[i:i+overlap] * fade_out + segment_output[:overlap] * fade_in
                result[i+overlap:i+segment_length] = segment_output[overlap:]  # Copiază restul segmentului

        return result / np.max(np.abs(result))  # Normalizează și returnează rezultatul

    # Folosim filtrul Wiener ca aproximare a semnalului curat
    clean_approx = wiener_output  # Folosește ieșirea Wiener ca aproximare a semnalului curat

    # Antrenăm modelul cu 50 epoci
    model = train_nn(clean_approx, noisy, epochs=50)  # Antrenează modelul neural
    nn_output = apply_nn(noisy, model)  # Aplică modelul pentru a obține rezultatul

    # Redăm fiecare metodă
    print("\nFiltru Wiener:")  # Afișează titlul pentru rezultatul Wiener
    display(Audio(wiener_output, rate=sr))  # Afișează player audio pentru rezultatul Wiener

    print("ICA:")  # Afișează titlul pentru rezultatul ICA
    display(Audio(ica_output, rate=sr))  # Afișează player audio pentru rezultatul ICA

    print("Rețea neuronală (50 epoci):")  # Afișează titlul pentru rezultatul rețelei neurale
    display(Audio(nn_output, rate=sr))  # Afișează player audio pentru rezultatul rețelei neurale

    # Afișăm spectrogramele
    plt.figure(figsize=(15, 12))  # Creează o figură de dimensiune mare
    plt.suptitle("Comparație spectrograme", fontsize=16)  # Adaugă un titlu principal

    plt.subplot(4, 1, 1)  # Prima subplotare pentru semnalul original
    D = librosa.amplitude_to_db(np.abs(librosa.stft(noisy)), ref=np.max)  # Calculează spectrograma în dB
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')  # Afișează spectrograma
    plt.colorbar(format='%+2.0f dB')  # Adaugă bară de culori
    plt.title("Semnal zgomotos original")  # Adaugă titlu

    plt.subplot(4, 1, 2)  # A doua subplotare pentru rezultatul Wiener
    D = librosa.amplitude_to_db(np.abs(librosa.stft(wiener_output)), ref=np.max)  # Calculează spectrograma
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')  # Afișează spectrograma
    plt.colorbar(format='%+2.0f dB')  # Adaugă bară de culori
    plt.title("Filtru Wiener")  # Adaugă titlu

    plt.subplot(4, 1, 3)  # A treia subplotare pentru rezultatul ICA
    D = librosa.amplitude_to_db(np.abs(librosa.stft(ica_output)), ref=np.max)  # Calculează spectrograma
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')  # Afișează spectrograma
    plt.colorbar(format='%+2.0f dB')  # Adaugă bară de culori
    plt.title("ICA")  # Adaugă titlu

    plt.subplot(4, 1, 4)  # A patra subplotare pentru rezultatul rețelei neurale
    D = librosa.amplitude_to_db(np.abs(librosa.stft(nn_output)), ref=np.max)  # Calculează spectrograma
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')  # Afișează spectrograma
    plt.colorbar(format='%+2.0f dB')  # Adaugă bară de culori
    plt.title("Rețea neuronală (50 epoci)")  # Adaugă titlu

    plt.tight_layout()  # Ajustează layout-ul
    plt.subplots_adjust(top=0.92)  # Ajustează spațiul de sus pentru titlul principal
    plt.show()  # Afișează figura

    # Evaluăm metodele
    def calculate_snr(reference, processed):  # Definește o funcție pentru calculul SNR
        noise = reference - processed  # Calculează diferența (zgomotul)
        signal_power = np.mean(reference**2)  # Calculează puterea semnalului de referință
        noise_power = np.mean(noise**2)  # Calculează puterea zgomotului
        if noise_power == 0:  # Verifică diviziunea la zero
            return float('inf')  # Returnează infinit dacă nu există zgomot
        return 10 * np.log10(signal_power / noise_power)  # Calculează și returnează SNR în dB

    # Folosim semnalul cu zgomot ca referință
    wiener_snr = calculate_snr(noisy, wiener_output)  # Calculează SNR pentru Wiener
    ica_snr = calculate_snr(noisy, ica_output)  # Calculează SNR pentru ICA
    nn_snr = calculate_snr(noisy, nn_output)  # Calculează SNR pentru rețeaua neurală

    methods = ['Wiener', 'ICA', 'Rețea neuronală']  # Definește lista numelor metodelor
    snr_values = [wiener_snr, ica_snr, nn_snr]  # Definește lista valorilor SNR

    # Afișăm grafic
    plt.figure(figsize=(10, 5))  # Creează o figură
    bars = plt.bar(methods, snr_values, color=['skyblue', 'lightgreen', 'coral'])  # Creează un grafic cu bare

    # Evidențiem cea mai bună metodă
    best_idx = np.argmax(snr_values)  # Găsește indexul celei mai bune metode
    bars[best_idx].set_color('green')  # Colorează bara corespunzătoare în verde

    plt.title('Comparație SNR între metode')  # Adaugă titlu
    plt.ylabel('SNR (dB)')  # Adaugă eticheta axei Y
    plt.grid(axis='y', linestyle='--', alpha=0.8)  # Adaugă grid

    # Adăugăm valorile pe grafic
    for i, v in enumerate(snr_values):  # Pentru fiecare valoare
        plt.text(i, v + 0.5, f"{v:.2f} dB", ha='center')  # Adaugă text cu valoarea

    plt.show()  # Afișează figura

    # Determinăm cea mai bună metodă
    best_method = methods[best_idx]  # Obține numele celei mai bune metode
    print(f"\nCea mai bună metodă: {best_method}")  # Afișează cea mai bună metodă

    # Comparație audio
    print("\nComparație audio (Original → Wiener → ICA → Rețea neuronală):")  # Afișează titlu pentru comparație
    silence = np.zeros(int(sr * 0.5))  # Creează un segment de tăcere de 0.5 secunde
    length = min(len(noisy), int(sr * 2))  # Limitează lungimea la maxim 2 secunde

    comparison = np.concatenate([  # Concatenează toate segmentele audio
        silence, noisy[:length],  # Tăcere urmat de original
        silence, wiener_output[:length],  # Tăcere urmat de Wiener
        silence, ica_output[:length],  # Tăcere urmat de ICA
        silence, nn_output[:length]  # Tăcere urmat de rețea neurală
    ])

    return Audio(comparison, rate=sr)  # Returnează un player audio cu toate segmentele

process_user_audio()  # Apelează funcția de procesare audio